{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "220b173d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.decomposition import LatentDirichletAllocation, TruncatedSVD\n",
    "from pprint import pprint"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "152150d0",
   "metadata": {},
   "source": [
    "# Base Processing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b1d9438",
   "metadata": {},
   "source": [
    "### Read in training & test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "51b50add",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 6914 entries, 0 to 6913\n",
      "Data columns (total 10 columns):\n",
      " #   Column       Non-Null Count  Dtype  \n",
      "---  ------       --------------  -----  \n",
      " 0   id           6914 non-null   object \n",
      " 1   X.sales      6914 non-null   int64  \n",
      " 2   cdate        6914 non-null   object \n",
      " 3   description  6512 non-null   object \n",
      " 4   version      6746 non-null   object \n",
      " 5   symbol       5555 non-null   object \n",
      " 6   ext          6914 non-null   object \n",
      " 7   fee1         6696 non-null   float64\n",
      " 8   fee2         6705 non-null   float64\n",
      " 9   total        6914 non-null   float64\n",
      "dtypes: float64(3), int64(1), object(6)\n",
      "memory usage: 540.3+ KB\n",
      "None\n",
      "\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 6914 entries, 0 to 6913\n",
      "Data columns (total 9 columns):\n",
      " #   Column       Non-Null Count  Dtype  \n",
      "---  ------       --------------  -----  \n",
      " 0   id           6914 non-null   object \n",
      " 1   X.sales      6914 non-null   int64  \n",
      " 2   cdate        6914 non-null   object \n",
      " 3   description  6537 non-null   object \n",
      " 4   version      6760 non-null   object \n",
      " 5   symbol       5532 non-null   object \n",
      " 6   ext          6914 non-null   object \n",
      " 7   fee1         6630 non-null   float64\n",
      " 8   fee2         6638 non-null   float64\n",
      "dtypes: float64(2), int64(1), object(6)\n",
      "memory usage: 486.3+ KB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# Load CSV to Dataframe\n",
    "PATH = 'data/'\n",
    "FILE_train = 'XYtr.csv'\n",
    "FILE_test = 'Xte.csv'\n",
    "\n",
    "raw_train = pd.read_csv(PATH + FILE_train)\n",
    "raw_test = pd.read_csv(PATH + FILE_test)\n",
    "\n",
    "# Description, version, symbol, fee1, and fee2 have missing values (NaN)\n",
    "print(raw_train.info())\n",
    "print()\n",
    "print(raw_test.info())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "116a8809",
   "metadata": {},
   "source": [
    "### size of the dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "94119985",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "raw_train shape:  (6914, 10)\n",
      "raw_test shape:  (6914, 9)\n"
     ]
    }
   ],
   "source": [
    "print('raw_train shape: ', raw_train.shape)\n",
    "print('raw_test shape: ', raw_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b4b28ea",
   "metadata": {},
   "source": [
    "### description"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "97dcb4f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "raw_train description missing values:  402\n",
      "raw_test description missing values:  377\n"
     ]
    }
   ],
   "source": [
    "print('raw_train description missing values: ', raw_train['description'].isnull().sum())\n",
    "print('raw_test description missing values: ', raw_test['description'].isnull().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "815f30bc",
   "metadata": {},
   "source": [
    "### version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "06e94f6f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "raw_train version:  ['3' 'None' 'unsupported' '4' nan '1' '2']\n",
      "raw_test version:  ['3' '4' 'None' nan 'unsupported' '1' '2']\n"
     ]
    }
   ],
   "source": [
    "print('raw_train version: ', raw_train['version'].unique())\n",
    "print('raw_test version: ', raw_test['version'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3be90418",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "raw_train version missing values:  168\n",
      "raw_test version missing values:  154\n"
     ]
    }
   ],
   "source": [
    "print('raw_train version missing values: ', raw_train['version'].isnull().sum())\n",
    "print('raw_test version missing values: ', raw_test['version'].isnull().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18f83f6f",
   "metadata": {},
   "source": [
    "### symbol"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "54f9f965",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "raw_train symbol:  417\n",
      "raw_test symbol:  415\n"
     ]
    }
   ],
   "source": [
    "# https://stackoverflow.com/questions/45759966/counting-unique-values-in-a-column-in-pandas-dataframe-like-in-qlik/45760042\n",
    "print('raw_train symbol: ', raw_train['symbol'].nunique())\n",
    "print('raw_test symbol: ', raw_test['symbol'].nunique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "80ef3671",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "raw_train symbol missing values:  1359\n",
      "raw_test symbol missing values:  1382\n"
     ]
    }
   ],
   "source": [
    "print('raw_train symbol missing values: ', raw_train['symbol'].isnull().sum())\n",
    "print('raw_test symbol missing values: ', raw_test['symbol'].isnull().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94edac07",
   "metadata": {},
   "source": [
    "### ext"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2daa8759",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "raw_train ext:  ['.png' '.jpg' '.gif']\n",
      "raw_test ext:  ['.png' '.gif' '.jpg']\n"
     ]
    }
   ],
   "source": [
    "print('raw_train ext: ', raw_train['ext'].unique())\n",
    "print('raw_test ext: ', raw_test['ext'].unique())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8bb84d40",
   "metadata": {},
   "source": [
    "### fee1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2a2c59e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "raw_train fee1 missing values:  218\n",
      "raw_test fee1 missing values:  284\n"
     ]
    }
   ],
   "source": [
    "print('raw_train fee1 missing values: ', raw_train['fee1'].isnull().sum())\n",
    "print('raw_test fee1 missing values: ', raw_test['fee1'].isnull().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14d5bfdd",
   "metadata": {},
   "source": [
    "### fee2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8ec3e444",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "raw_train fee2 missing values:  209\n",
      "raw_test fee2 missing values:  276\n"
     ]
    }
   ],
   "source": [
    "print('raw_train fee2 missing values: ', raw_train['fee2'].isnull().sum())\n",
    "print('raw_test fee2 missing values: ', raw_test['fee2'].isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0518aa62",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_clean = raw_train.copy()\n",
    "test_clean = raw_test.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da8a0be8",
   "metadata": {},
   "source": [
    "### Data Cleaning for training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "1920f532",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 6914 entries, 0 to 6913\n",
      "Data columns (total 10 columns):\n",
      " #   Column       Non-Null Count  Dtype  \n",
      "---  ------       --------------  -----  \n",
      " 0   id           6914 non-null   object \n",
      " 1   X.sales      6914 non-null   int64  \n",
      " 2   cdate        6914 non-null   object \n",
      " 3   description  6914 non-null   object \n",
      " 4   version      6914 non-null   object \n",
      " 5   symbol       6914 non-null   object \n",
      " 6   ext          6914 non-null   object \n",
      " 7   fee1         6914 non-null   float64\n",
      " 8   fee2         6914 non-null   float64\n",
      " 9   total        6914 non-null   float64\n",
      "dtypes: float64(3), int64(1), object(6)\n",
      "memory usage: 540.3+ KB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# description: use the token None to mean no description\n",
    "train_clean['description'] = train_clean['description'].fillna('None')\n",
    "\n",
    "# version: Has 'None' category. Set nan to 'None'. \n",
    "#print(train_train['version'].unique())\n",
    "train_clean['version'] = train_clean['version'].fillna('None')\n",
    "\n",
    "# symbol: 5 digit symbols. Set to 00000 to represent None.\n",
    "# print(df_train['symbol'].unique())\n",
    "train_clean['symbol'] = train_clean['symbol'].fillna('00000')\n",
    "\n",
    "\n",
    "# fee1: Small number misssin. Fill with the mean.\n",
    "#df_train['fee1'] = df_train['fee1'].fillna((df_train['fee1'].mean()))\n",
    "# https://www.w3resource.com/python-exercises/pandas/missing-values/python-pandas-missing-values-exercise-14.php\n",
    "train_clean['fee1'].fillna(train_clean['fee1'].median(), inplace=True)\n",
    "                                           \n",
    "# fee2: Small number misssin. Fill with the mean.\n",
    "#df_train['fee2'] = df_train['fee2'].fillna((df_train['fee2'].mean()))\n",
    "train_clean['fee2'].fillna(train_clean['fee2'].median(), inplace=True)\n",
    "\n",
    "\n",
    "print(train_clean.info())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41b0b1b6",
   "metadata": {},
   "source": [
    "### Data Cleaning for test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "91c3a6bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 6914 entries, 0 to 6913\n",
      "Data columns (total 9 columns):\n",
      " #   Column       Non-Null Count  Dtype  \n",
      "---  ------       --------------  -----  \n",
      " 0   id           6914 non-null   object \n",
      " 1   X.sales      6914 non-null   int64  \n",
      " 2   cdate        6914 non-null   object \n",
      " 3   description  6914 non-null   object \n",
      " 4   version      6914 non-null   object \n",
      " 5   symbol       6914 non-null   object \n",
      " 6   ext          6914 non-null   object \n",
      " 7   fee1         6914 non-null   float64\n",
      " 8   fee2         6914 non-null   float64\n",
      "dtypes: float64(2), int64(1), object(6)\n",
      "memory usage: 486.3+ KB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# description: use the token None to mean no description\n",
    "test_clean['description'] = test_clean['description'].fillna('None')\n",
    "\n",
    "# version: Has 'None' category. Set nan to 'None'. \n",
    "test_clean['version'] = test_clean['version'].fillna('None')\n",
    "\n",
    "# symbol: 5 digit symbols. Set to 00000 to represent None.\n",
    "test_clean['symbol'] = test_clean['symbol'].fillna('00000')\n",
    "\n",
    "# fee1: Small number misssin. Fill with the mean.\n",
    "test_clean['fee1'].fillna(test_clean['fee1'].median(), inplace=True)\n",
    "                                           \n",
    "# fee2: Small number misssin. Fill with the mean.\n",
    "test_clean['fee2'].fillna(test_clean['fee2'].median(), inplace=True)\n",
    "\n",
    "\n",
    "print(test_clean.info())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50fb0bce",
   "metadata": {},
   "source": [
    "### Data preprocessing for training & test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "64e9b53d",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_processed = train_clean.copy()\n",
    "test_processed = test_clean.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "4744a669",
   "metadata": {},
   "outputs": [],
   "source": [
    "# cdate: change dates to float\n",
    "tr_date = train_processed['cdate']\n",
    "train_processed['cdate'] = pd.to_datetime(tr_date).values.astype(np.float64)/8.64e+13\n",
    "\n",
    "te_date = test_processed['cdate']\n",
    "test_processed['cdate'] = pd.to_datetime(te_date).values.astype(np.float64)/8.64e+13"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "22ae985d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# X.sales: change from int to float\n",
    "train_processed['X.sales'] = train_processed['X.sales'].astype(np.float64)\n",
    "test_processed['X.sales'] = test_processed['X.sales'].astype(np.float64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "53c92919",
   "metadata": {},
   "outputs": [],
   "source": [
    "# obtain unique values from each dataset\n",
    "train_symbols = set(train_processed['symbol'].unique())\n",
    "test_symbols = set(test_processed['symbol'].unique())\n",
    "\n",
    "# union all the values\n",
    "# https://stackoverflow.com/questions/52976664/python-differences-between-two-lists\n",
    "# # https://www.programiz.com/python-programming/methods/set/union\n",
    "all_symbols = train_symbols.union(test_symbols)\n",
    "\n",
    "# values not included in train set\n",
    "train_required_symbols = list(all_symbols - train_symbols)\n",
    "\n",
    "# values not included in test set\n",
    "test_required_symbols = list(all_symbols - test_symbols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "0197e2f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# one-hot encoding on version, symbol and ext\n",
    "train_processed = pd.get_dummies(train_processed, columns = ['version', 'ext', 'symbol'], drop_first = False, prefix = ['version', 'ext', 'symbol'])\n",
    "test_processed = pd.get_dummies(test_processed, columns = ['version', 'ext', 'symbol'], drop_first = False, prefix = ['version', 'ext', 'symbol'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "aa528fdb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/pop21/Documents/STAT-440/nft/jason/venv/lib/python3.9/site-packages/IPython/core/interactiveshell.py:3364: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead.  To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  if (await self.run_code(code, result,  async_=asy)):\n"
     ]
    }
   ],
   "source": [
    "# https://stackoverflow.com/questions/18674064/how-do-i-insert-a-column-at-a-specific-column-index-in-pandas\n",
    "for train_syms in train_required_symbols:\n",
    "    train_processed.insert(train_processed.shape[1], str('symbol_') + train_syms, 0)\n",
    "train_base = train_processed.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "cd2bbd3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "for test_syms in test_required_symbols:\n",
    "    test_processed.insert(test_processed.shape[1], str('symbol_') + test_syms, 0)\n",
    "test_base = test_processed.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "2aee7ff2",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_base = train_processed.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "7dc26c55",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_base = test_processed.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60745ea1",
   "metadata": {},
   "source": [
    "# Text Feature Extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "bd6fb211",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train description missing values:  0\n",
      "test description missing values:  0\n"
     ]
    }
   ],
   "source": [
    "# Check for missing values before processing\n",
    "print('train description missing values: ', train_base['description'].isnull().sum())\n",
    "print('test description missing values: ', test_base['description'].isnull().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea42391f",
   "metadata": {},
   "source": [
    "### Create a corpus using training and test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "bbcc8ce2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create corpus using training and test data\n",
    "corpus = list(train_base['description'])+list(test_base['description'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ba74f2b",
   "metadata": {},
   "source": [
    "### Create a Document-Word matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "537baa99",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a Vectorizer Object\n",
    "# remove tokens that appear in 10% of the documents\n",
    "# remove unique tokens that appear in, at most, 2 documents\n",
    "vectorizer = CountVectorizer(max_df=0.1, min_df=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "57752513",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encode the documents in a count matrix\n",
    "corpus_vectorized = vectorizer.fit_transform(corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "a5a7d1cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "feature name:  ['002n7' '00b0d' '00jhg' ... 'zztgg' 'zzvdf' 'zzw3j']\n",
      "feature size:  10566\n",
      "matrix dimension:  (13828, 10566)\n"
     ]
    }
   ],
   "source": [
    "# Feature names and size\n",
    "print('feature name: ', vectorizer.get_feature_names_out())\n",
    "print('feature size: ', len(vectorizer.get_feature_names_out()))\n",
    "\n",
    "# dimension of a sparse matrix of documents (row) vs number of unique words\n",
    "print('matrix dimension: ', corpus_vectorized.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "e489f74d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>002n7</th>\n",
       "      <th>00b0d</th>\n",
       "      <th>00jhg</th>\n",
       "      <th>00ud9</th>\n",
       "      <th>00xck</th>\n",
       "      <th>01abs</th>\n",
       "      <th>01fnu</th>\n",
       "      <th>01jsj</th>\n",
       "      <th>01k0e</th>\n",
       "      <th>01nrz</th>\n",
       "      <th>...</th>\n",
       "      <th>zzhb3</th>\n",
       "      <th>zzht0</th>\n",
       "      <th>zzlz3</th>\n",
       "      <th>zznp1</th>\n",
       "      <th>zzns7</th>\n",
       "      <th>zzpvk</th>\n",
       "      <th>zzr1c</th>\n",
       "      <th>zztgg</th>\n",
       "      <th>zzvdf</th>\n",
       "      <th>zzw3j</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13823</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13824</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13825</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13826</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13827</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>13828 rows × 10566 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       002n7  00b0d  00jhg  00ud9  00xck  01abs  01fnu  01jsj  01k0e  01nrz  \\\n",
       "0          0      0      0      0      0      0      0      0      0      0   \n",
       "1          0      0      0      0      0      0      0      0      0      0   \n",
       "2          0      0      0      0      0      0      0      0      0      0   \n",
       "3          0      0      0      0      0      0      0      0      0      0   \n",
       "4          0      0      0      0      0      0      0      0      0      0   \n",
       "...      ...    ...    ...    ...    ...    ...    ...    ...    ...    ...   \n",
       "13823      0      0      0      0      0      0      0      0      0      0   \n",
       "13824      0      0      0      0      0      0      0      0      0      0   \n",
       "13825      0      0      0      0      0      0      0      0      0      0   \n",
       "13826      0      0      0      0      0      0      0      0      0      0   \n",
       "13827      0      0      0      0      0      0      0      0      0      0   \n",
       "\n",
       "       ...  zzhb3  zzht0  zzlz3  zznp1  zzns7  zzpvk  zzr1c  zztgg  zzvdf  \\\n",
       "0      ...      0      0      0      0      0      0      0      0      0   \n",
       "1      ...      0      0      0      0      0      0      0      0      0   \n",
       "2      ...      0      0      0      0      0      0      0      0      0   \n",
       "3      ...      0      0      0      0      0      0      0      0      0   \n",
       "4      ...      0      0      0      0      0      0      0      0      0   \n",
       "...    ...    ...    ...    ...    ...    ...    ...    ...    ...    ...   \n",
       "13823  ...      0      0      0      0      0      0      0      0      0   \n",
       "13824  ...      0      0      0      0      0      0      0      0      0   \n",
       "13825  ...      0      0      0      0      0      0      0      0      0   \n",
       "13826  ...      0      0      0      0      0      0      0      0      0   \n",
       "13827  ...      0      0      0      0      0      0      0      0      0   \n",
       "\n",
       "       zzw3j  \n",
       "0          0  \n",
       "1          0  \n",
       "2          0  \n",
       "3          0  \n",
       "4          0  \n",
       "...      ...  \n",
       "13823      0  \n",
       "13824      0  \n",
       "13825      0  \n",
       "13826      0  \n",
       "13827      0  \n",
       "\n",
       "[13828 rows x 10566 columns]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# A sparse matrix of documents (row) vs number of unique words\n",
    "count_array = corpus_vectorized.toarray()\n",
    "corpus_df = pd.DataFrame(data=count_array,columns = vectorizer.get_feature_names_out())\n",
    "corpus_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc21fb91",
   "metadata": {},
   "source": [
    "### Build a LDA model for topic modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "893696de",
   "metadata": {},
   "outputs": [],
   "source": [
    "lda_model = LatentDirichletAllocation(n_components = 10,\n",
    "                                     learning_method = 'online',\n",
    "                                      learning_decay = 0.9,\n",
    "                                      random_state=100, \n",
    "                                      batch_size=128, \n",
    "                                      evaluate_every = -1, \n",
    "                                      n_jobs = -1)\n",
    "\n",
    "lda_output = lda_model.fit_transform(corpus_vectorized)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "733d9dae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(13828, 10)\n",
      "LatentDirichletAllocation(learning_decay=0.9, learning_method='online',\n",
      "                          n_jobs=-1, random_state=100)\n"
     ]
    }
   ],
   "source": [
    "print(lda_output.shape)\n",
    "print(lda_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3807c0a",
   "metadata": {},
   "source": [
    "### Separate the dataframe back to train and test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "a9862492",
   "metadata": {},
   "outputs": [],
   "source": [
    "topicnames = [\"Topic\" + str(i) for i in range(lda_model.n_components)]\n",
    "train_document_topic = pd.DataFrame(np.round(lda_output[0:6914,], 8), columns = topicnames)\n",
    "test_document_topic = pd.DataFrame(np.round(lda_output[6914:13828,], 8), columns = topicnames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "d666fd9f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Topic0</th>\n",
       "      <th>Topic1</th>\n",
       "      <th>Topic2</th>\n",
       "      <th>Topic3</th>\n",
       "      <th>Topic4</th>\n",
       "      <th>Topic5</th>\n",
       "      <th>Topic6</th>\n",
       "      <th>Topic7</th>\n",
       "      <th>Topic8</th>\n",
       "      <th>Topic9</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.005557</td>\n",
       "      <td>0.005556</td>\n",
       "      <td>0.005561</td>\n",
       "      <td>0.005556</td>\n",
       "      <td>0.005558</td>\n",
       "      <td>0.005556</td>\n",
       "      <td>0.005556</td>\n",
       "      <td>0.005558</td>\n",
       "      <td>0.949986</td>\n",
       "      <td>0.005556</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.016667</td>\n",
       "      <td>0.016667</td>\n",
       "      <td>0.016667</td>\n",
       "      <td>0.179592</td>\n",
       "      <td>0.016678</td>\n",
       "      <td>0.016667</td>\n",
       "      <td>0.016667</td>\n",
       "      <td>0.016669</td>\n",
       "      <td>0.687062</td>\n",
       "      <td>0.016667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.700000</td>\n",
       "      <td>0.033333</td>\n",
       "      <td>0.033333</td>\n",
       "      <td>0.033333</td>\n",
       "      <td>0.033333</td>\n",
       "      <td>0.033333</td>\n",
       "      <td>0.033333</td>\n",
       "      <td>0.033333</td>\n",
       "      <td>0.033333</td>\n",
       "      <td>0.033333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.004167</td>\n",
       "      <td>0.004167</td>\n",
       "      <td>0.004167</td>\n",
       "      <td>0.004167</td>\n",
       "      <td>0.004167</td>\n",
       "      <td>0.004167</td>\n",
       "      <td>0.004167</td>\n",
       "      <td>0.004167</td>\n",
       "      <td>0.962499</td>\n",
       "      <td>0.004167</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.050000</td>\n",
       "      <td>0.050000</td>\n",
       "      <td>0.050000</td>\n",
       "      <td>0.550000</td>\n",
       "      <td>0.050000</td>\n",
       "      <td>0.050000</td>\n",
       "      <td>0.050000</td>\n",
       "      <td>0.050000</td>\n",
       "      <td>0.050000</td>\n",
       "      <td>0.050000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6909</th>\n",
       "      <td>0.115124</td>\n",
       "      <td>0.001961</td>\n",
       "      <td>0.001961</td>\n",
       "      <td>0.001961</td>\n",
       "      <td>0.001961</td>\n",
       "      <td>0.094700</td>\n",
       "      <td>0.001961</td>\n",
       "      <td>0.776450</td>\n",
       "      <td>0.001961</td>\n",
       "      <td>0.001961</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6910</th>\n",
       "      <td>0.033333</td>\n",
       "      <td>0.699982</td>\n",
       "      <td>0.033333</td>\n",
       "      <td>0.033333</td>\n",
       "      <td>0.033351</td>\n",
       "      <td>0.033333</td>\n",
       "      <td>0.033333</td>\n",
       "      <td>0.033333</td>\n",
       "      <td>0.033333</td>\n",
       "      <td>0.033333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6911</th>\n",
       "      <td>0.003125</td>\n",
       "      <td>0.003125</td>\n",
       "      <td>0.003125</td>\n",
       "      <td>0.003125</td>\n",
       "      <td>0.003125</td>\n",
       "      <td>0.003125</td>\n",
       "      <td>0.003125</td>\n",
       "      <td>0.003125</td>\n",
       "      <td>0.971874</td>\n",
       "      <td>0.003125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6912</th>\n",
       "      <td>0.010000</td>\n",
       "      <td>0.510000</td>\n",
       "      <td>0.010001</td>\n",
       "      <td>0.164334</td>\n",
       "      <td>0.010001</td>\n",
       "      <td>0.010000</td>\n",
       "      <td>0.010000</td>\n",
       "      <td>0.010001</td>\n",
       "      <td>0.255661</td>\n",
       "      <td>0.010002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6913</th>\n",
       "      <td>0.050000</td>\n",
       "      <td>0.050000</td>\n",
       "      <td>0.050000</td>\n",
       "      <td>0.550000</td>\n",
       "      <td>0.050000</td>\n",
       "      <td>0.050000</td>\n",
       "      <td>0.050000</td>\n",
       "      <td>0.050000</td>\n",
       "      <td>0.050000</td>\n",
       "      <td>0.050000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>6914 rows × 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        Topic0    Topic1    Topic2    Topic3    Topic4    Topic5    Topic6  \\\n",
       "0     0.005557  0.005556  0.005561  0.005556  0.005558  0.005556  0.005556   \n",
       "1     0.016667  0.016667  0.016667  0.179592  0.016678  0.016667  0.016667   \n",
       "2     0.700000  0.033333  0.033333  0.033333  0.033333  0.033333  0.033333   \n",
       "3     0.004167  0.004167  0.004167  0.004167  0.004167  0.004167  0.004167   \n",
       "4     0.050000  0.050000  0.050000  0.550000  0.050000  0.050000  0.050000   \n",
       "...        ...       ...       ...       ...       ...       ...       ...   \n",
       "6909  0.115124  0.001961  0.001961  0.001961  0.001961  0.094700  0.001961   \n",
       "6910  0.033333  0.699982  0.033333  0.033333  0.033351  0.033333  0.033333   \n",
       "6911  0.003125  0.003125  0.003125  0.003125  0.003125  0.003125  0.003125   \n",
       "6912  0.010000  0.510000  0.010001  0.164334  0.010001  0.010000  0.010000   \n",
       "6913  0.050000  0.050000  0.050000  0.550000  0.050000  0.050000  0.050000   \n",
       "\n",
       "        Topic7    Topic8    Topic9  \n",
       "0     0.005558  0.949986  0.005556  \n",
       "1     0.016669  0.687062  0.016667  \n",
       "2     0.033333  0.033333  0.033333  \n",
       "3     0.004167  0.962499  0.004167  \n",
       "4     0.050000  0.050000  0.050000  \n",
       "...        ...       ...       ...  \n",
       "6909  0.776450  0.001961  0.001961  \n",
       "6910  0.033333  0.033333  0.033333  \n",
       "6911  0.003125  0.971874  0.003125  \n",
       "6912  0.010001  0.255661  0.010002  \n",
       "6913  0.050000  0.050000  0.050000  \n",
       "\n",
       "[6914 rows x 10 columns]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_document_topic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "89115073",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Topic0</th>\n",
       "      <th>Topic1</th>\n",
       "      <th>Topic2</th>\n",
       "      <th>Topic3</th>\n",
       "      <th>Topic4</th>\n",
       "      <th>Topic5</th>\n",
       "      <th>Topic6</th>\n",
       "      <th>Topic7</th>\n",
       "      <th>Topic8</th>\n",
       "      <th>Topic9</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.009091</td>\n",
       "      <td>0.009091</td>\n",
       "      <td>0.009091</td>\n",
       "      <td>0.009091</td>\n",
       "      <td>0.009091</td>\n",
       "      <td>0.009091</td>\n",
       "      <td>0.009091</td>\n",
       "      <td>0.009091</td>\n",
       "      <td>0.009091</td>\n",
       "      <td>0.918180</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.050000</td>\n",
       "      <td>0.050000</td>\n",
       "      <td>0.050000</td>\n",
       "      <td>0.550000</td>\n",
       "      <td>0.050000</td>\n",
       "      <td>0.050000</td>\n",
       "      <td>0.050000</td>\n",
       "      <td>0.050000</td>\n",
       "      <td>0.050000</td>\n",
       "      <td>0.050000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.128232</td>\n",
       "      <td>0.007693</td>\n",
       "      <td>0.186306</td>\n",
       "      <td>0.007693</td>\n",
       "      <td>0.007693</td>\n",
       "      <td>0.007695</td>\n",
       "      <td>0.007697</td>\n",
       "      <td>0.631605</td>\n",
       "      <td>0.007694</td>\n",
       "      <td>0.007692</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.003226</td>\n",
       "      <td>0.003227</td>\n",
       "      <td>0.796178</td>\n",
       "      <td>0.003226</td>\n",
       "      <td>0.003226</td>\n",
       "      <td>0.003226</td>\n",
       "      <td>0.003226</td>\n",
       "      <td>0.064850</td>\n",
       "      <td>0.046840</td>\n",
       "      <td>0.072775</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.012501</td>\n",
       "      <td>0.012500</td>\n",
       "      <td>0.012500</td>\n",
       "      <td>0.012500</td>\n",
       "      <td>0.887497</td>\n",
       "      <td>0.012500</td>\n",
       "      <td>0.012500</td>\n",
       "      <td>0.012501</td>\n",
       "      <td>0.012500</td>\n",
       "      <td>0.012500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6909</th>\n",
       "      <td>0.001220</td>\n",
       "      <td>0.001220</td>\n",
       "      <td>0.001220</td>\n",
       "      <td>0.001220</td>\n",
       "      <td>0.001220</td>\n",
       "      <td>0.001220</td>\n",
       "      <td>0.989024</td>\n",
       "      <td>0.001220</td>\n",
       "      <td>0.001220</td>\n",
       "      <td>0.001220</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6910</th>\n",
       "      <td>0.002565</td>\n",
       "      <td>0.642044</td>\n",
       "      <td>0.182279</td>\n",
       "      <td>0.157726</td>\n",
       "      <td>0.002564</td>\n",
       "      <td>0.002564</td>\n",
       "      <td>0.002564</td>\n",
       "      <td>0.002564</td>\n",
       "      <td>0.002564</td>\n",
       "      <td>0.002564</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6911</th>\n",
       "      <td>0.025000</td>\n",
       "      <td>0.025000</td>\n",
       "      <td>0.025000</td>\n",
       "      <td>0.025000</td>\n",
       "      <td>0.775000</td>\n",
       "      <td>0.025000</td>\n",
       "      <td>0.025000</td>\n",
       "      <td>0.025000</td>\n",
       "      <td>0.025000</td>\n",
       "      <td>0.025000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6912</th>\n",
       "      <td>0.004762</td>\n",
       "      <td>0.004762</td>\n",
       "      <td>0.004762</td>\n",
       "      <td>0.004762</td>\n",
       "      <td>0.957142</td>\n",
       "      <td>0.004762</td>\n",
       "      <td>0.004762</td>\n",
       "      <td>0.004762</td>\n",
       "      <td>0.004762</td>\n",
       "      <td>0.004762</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6913</th>\n",
       "      <td>0.700000</td>\n",
       "      <td>0.033333</td>\n",
       "      <td>0.033333</td>\n",
       "      <td>0.033333</td>\n",
       "      <td>0.033333</td>\n",
       "      <td>0.033333</td>\n",
       "      <td>0.033333</td>\n",
       "      <td>0.033333</td>\n",
       "      <td>0.033333</td>\n",
       "      <td>0.033333</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>6914 rows × 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        Topic0    Topic1    Topic2    Topic3    Topic4    Topic5    Topic6  \\\n",
       "0     0.009091  0.009091  0.009091  0.009091  0.009091  0.009091  0.009091   \n",
       "1     0.050000  0.050000  0.050000  0.550000  0.050000  0.050000  0.050000   \n",
       "2     0.128232  0.007693  0.186306  0.007693  0.007693  0.007695  0.007697   \n",
       "3     0.003226  0.003227  0.796178  0.003226  0.003226  0.003226  0.003226   \n",
       "4     0.012501  0.012500  0.012500  0.012500  0.887497  0.012500  0.012500   \n",
       "...        ...       ...       ...       ...       ...       ...       ...   \n",
       "6909  0.001220  0.001220  0.001220  0.001220  0.001220  0.001220  0.989024   \n",
       "6910  0.002565  0.642044  0.182279  0.157726  0.002564  0.002564  0.002564   \n",
       "6911  0.025000  0.025000  0.025000  0.025000  0.775000  0.025000  0.025000   \n",
       "6912  0.004762  0.004762  0.004762  0.004762  0.957142  0.004762  0.004762   \n",
       "6913  0.700000  0.033333  0.033333  0.033333  0.033333  0.033333  0.033333   \n",
       "\n",
       "        Topic7    Topic8    Topic9  \n",
       "0     0.009091  0.009091  0.918180  \n",
       "1     0.050000  0.050000  0.050000  \n",
       "2     0.631605  0.007694  0.007692  \n",
       "3     0.064850  0.046840  0.072775  \n",
       "4     0.012501  0.012500  0.012500  \n",
       "...        ...       ...       ...  \n",
       "6909  0.001220  0.001220  0.001220  \n",
       "6910  0.002564  0.002564  0.002564  \n",
       "6911  0.025000  0.025000  0.025000  \n",
       "6912  0.004762  0.004762  0.004762  \n",
       "6913  0.033333  0.033333  0.033333  \n",
       "\n",
       "[6914 rows x 10 columns]"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_document_topic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "2417b3fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: image feature extraction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b700a124",
   "metadata": {},
   "source": [
    "# Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "4ab79608",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression, SGDRegressor\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, GridSearchCV\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94e40ab5",
   "metadata": {},
   "source": [
    "### Preprocessing - concatenate text features to base dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "ca99c686",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6914, 599)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_concatenated = pd.concat([train_base, train_document_topic], axis=1)\n",
    "train_concatenated = train_concatenated.drop(['id', 'description'], axis=1)\n",
    "train_concatenated.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "36cfc1eb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6914, 598)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_concatenated = pd.concat([test_base, test_document_topic], axis=1)\n",
    "test_concatenated = test_concatenated.drop(['id', 'description'], axis=1)\n",
    "test_concatenated.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c5a3670",
   "metadata": {},
   "source": [
    "### Preprocessing - train-test-split to both train and test dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "aa6cd2e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "y = train_concatenated['total'].copy()\n",
    "X = train_concatenated.drop(['total'], axis=1).copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02c4b156",
   "metadata": {},
   "outputs": [],
   "source": [
    "#y = train_base['total'].copy()\n",
    "#X = train_base.drop(['id', 'description', 'total'], axis=1).copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "2e379c7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(X, y, train_size=0.75, test_size=0.25, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91bcbd96",
   "metadata": {},
   "source": [
    "# Make a new section for your models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f44311c",
   "metadata": {},
   "source": [
    "### Linear Regressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "6efb8a8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "OLS = LinearRegression().fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "4b645e3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "OLS_predictions = OLS.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "0ac75a15",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "17.901943932140455"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_absolute_error(y_test, OLS_predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76a165e7",
   "metadata": {},
   "source": [
    "### SGD Regressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "ab2c514b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# always standardize input\n",
    "scaler = StandardScaler()\n",
    "x_train = scaler.fit_transform(x_train)\n",
    "x_test = scaler.transform(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "f3c10dc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "SGD = SGDRegressor(loss = 'epsilon_insensitive', alpha = 0, epsilon = 0).fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "c4f01f39",
   "metadata": {},
   "outputs": [],
   "source": [
    "SGD_predictions = SGD.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "9b26891d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "11.534553563892858"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_absolute_error(y_test, SGD_predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "710028b6",
   "metadata": {},
   "source": [
    "### Tuning SGD Regressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "53753db6",
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid = {'alpha':[0.1,0.01, 0],\n",
    "              'learning_rate':['constant','optimal','invscaling','adaptive'],\n",
    "              'max_iter':[1000,2000],\n",
    "              'penalty':['l2','l1','elasticnet'],\n",
    "              'loss':['huber', 'epsilon_insensitive','squared_epsilon_insensitive', 'squared_error'],\n",
    "              'eta0': [0.01, 1, 10]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "d5193745",
   "metadata": {},
   "outputs": [],
   "source": [
    "sgd_ = SGDRegressor(random_state = 1)\n",
    "g_search = GridSearchCV(estimator = sgd_, param_grid = param_grid, cv = 3, n_jobs = 1, verbose = 0, return_train_score=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "b1098d63",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/pop21/Documents/STAT-440/nft/jason/venv/lib/python3.9/site-packages/sklearn/linear_model/_stochastic_gradient.py:1503: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/home/pop21/Documents/STAT-440/nft/jason/venv/lib/python3.9/site-packages/sklearn/linear_model/_stochastic_gradient.py:1503: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/home/pop21/Documents/STAT-440/nft/jason/venv/lib/python3.9/site-packages/sklearn/linear_model/_stochastic_gradient.py:1503: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/home/pop21/Documents/STAT-440/nft/jason/venv/lib/python3.9/site-packages/sklearn/linear_model/_stochastic_gradient.py:1503: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/home/pop21/Documents/STAT-440/nft/jason/venv/lib/python3.9/site-packages/sklearn/linear_model/_stochastic_gradient.py:1503: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/home/pop21/Documents/STAT-440/nft/jason/venv/lib/python3.9/site-packages/sklearn/linear_model/_stochastic_gradient.py:1503: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/home/pop21/Documents/STAT-440/nft/jason/venv/lib/python3.9/site-packages/sklearn/linear_model/_stochastic_gradient.py:1503: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/home/pop21/Documents/STAT-440/nft/jason/venv/lib/python3.9/site-packages/sklearn/linear_model/_stochastic_gradient.py:1503: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/home/pop21/Documents/STAT-440/nft/jason/venv/lib/python3.9/site-packages/sklearn/linear_model/_stochastic_gradient.py:1503: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/home/pop21/Documents/STAT-440/nft/jason/venv/lib/python3.9/site-packages/sklearn/linear_model/_stochastic_gradient.py:1503: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/home/pop21/Documents/STAT-440/nft/jason/venv/lib/python3.9/site-packages/sklearn/linear_model/_stochastic_gradient.py:1503: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/home/pop21/Documents/STAT-440/nft/jason/venv/lib/python3.9/site-packages/sklearn/linear_model/_stochastic_gradient.py:1503: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/home/pop21/Documents/STAT-440/nft/jason/venv/lib/python3.9/site-packages/sklearn/linear_model/_stochastic_gradient.py:1503: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/home/pop21/Documents/STAT-440/nft/jason/venv/lib/python3.9/site-packages/sklearn/linear_model/_stochastic_gradient.py:1503: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/home/pop21/Documents/STAT-440/nft/jason/venv/lib/python3.9/site-packages/sklearn/linear_model/_stochastic_gradient.py:1503: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/home/pop21/Documents/STAT-440/nft/jason/venv/lib/python3.9/site-packages/sklearn/linear_model/_stochastic_gradient.py:1503: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/home/pop21/Documents/STAT-440/nft/jason/venv/lib/python3.9/site-packages/sklearn/linear_model/_stochastic_gradient.py:1503: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/home/pop21/Documents/STAT-440/nft/jason/venv/lib/python3.9/site-packages/sklearn/linear_model/_stochastic_gradient.py:1503: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/home/pop21/Documents/STAT-440/nft/jason/venv/lib/python3.9/site-packages/sklearn/linear_model/_stochastic_gradient.py:1503: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/home/pop21/Documents/STAT-440/nft/jason/venv/lib/python3.9/site-packages/sklearn/linear_model/_stochastic_gradient.py:1503: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/home/pop21/Documents/STAT-440/nft/jason/venv/lib/python3.9/site-packages/sklearn/linear_model/_stochastic_gradient.py:1503: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/home/pop21/Documents/STAT-440/nft/jason/venv/lib/python3.9/site-packages/sklearn/linear_model/_stochastic_gradient.py:1503: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/home/pop21/Documents/STAT-440/nft/jason/venv/lib/python3.9/site-packages/sklearn/linear_model/_stochastic_gradient.py:1503: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/home/pop21/Documents/STAT-440/nft/jason/venv/lib/python3.9/site-packages/sklearn/linear_model/_stochastic_gradient.py:1503: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/home/pop21/Documents/STAT-440/nft/jason/venv/lib/python3.9/site-packages/sklearn/linear_model/_stochastic_gradient.py:1503: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/home/pop21/Documents/STAT-440/nft/jason/venv/lib/python3.9/site-packages/sklearn/linear_model/_stochastic_gradient.py:1503: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/home/pop21/Documents/STAT-440/nft/jason/venv/lib/python3.9/site-packages/sklearn/linear_model/_stochastic_gradient.py:1503: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/home/pop21/Documents/STAT-440/nft/jason/venv/lib/python3.9/site-packages/sklearn/linear_model/_stochastic_gradient.py:1503: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_8599/2660616166.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mg_search\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m;\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mg_search\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbest_params_\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/STAT-440/nft/jason/venv/lib/python3.9/site-packages/sklearn/model_selection/_search.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, groups, **fit_params)\u001b[0m\n\u001b[1;32m    889\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mresults\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    890\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 891\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_run_search\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mevaluate_candidates\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    892\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    893\u001b[0m             \u001b[0;31m# multimetric is determined here because in the case of a callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/STAT-440/nft/jason/venv/lib/python3.9/site-packages/sklearn/model_selection/_search.py\u001b[0m in \u001b[0;36m_run_search\u001b[0;34m(self, evaluate_candidates)\u001b[0m\n\u001b[1;32m   1390\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_run_search\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mevaluate_candidates\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1391\u001b[0m         \u001b[0;34m\"\"\"Search all candidates in param_grid\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1392\u001b[0;31m         \u001b[0mevaluate_candidates\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mParameterGrid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparam_grid\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1393\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1394\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/STAT-440/nft/jason/venv/lib/python3.9/site-packages/sklearn/model_selection/_search.py\u001b[0m in \u001b[0;36mevaluate_candidates\u001b[0;34m(candidate_params, cv, more_results)\u001b[0m\n\u001b[1;32m    836\u001b[0m                     )\n\u001b[1;32m    837\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 838\u001b[0;31m                 out = parallel(\n\u001b[0m\u001b[1;32m    839\u001b[0m                     delayed(_fit_and_score)(\n\u001b[1;32m    840\u001b[0m                         \u001b[0mclone\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbase_estimator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/STAT-440/nft/jason/venv/lib/python3.9/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   1044\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_iterating\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_original_iterator\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1045\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1046\u001b[0;31m             \u001b[0;32mwhile\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdispatch_one_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1047\u001b[0m                 \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1048\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/STAT-440/nft/jason/venv/lib/python3.9/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36mdispatch_one_batch\u001b[0;34m(self, iterator)\u001b[0m\n\u001b[1;32m    859\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    860\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 861\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dispatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtasks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    862\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    863\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/STAT-440/nft/jason/venv/lib/python3.9/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m_dispatch\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    777\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    778\u001b[0m             \u001b[0mjob_idx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jobs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 779\u001b[0;31m             \u001b[0mjob\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply_async\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    780\u001b[0m             \u001b[0;31m# A job can complete so quickly than its callback is\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    781\u001b[0m             \u001b[0;31m# called before we get here, causing self._jobs to\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/STAT-440/nft/jason/venv/lib/python3.9/site-packages/joblib/_parallel_backends.py\u001b[0m in \u001b[0;36mapply_async\u001b[0;34m(self, func, callback)\u001b[0m\n\u001b[1;32m    206\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mapply_async\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    207\u001b[0m         \u001b[0;34m\"\"\"Schedule a func to be run\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 208\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mImmediateResult\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    209\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    210\u001b[0m             \u001b[0mcallback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/STAT-440/nft/jason/venv/lib/python3.9/site-packages/joblib/_parallel_backends.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    570\u001b[0m         \u001b[0;31m# Don't delay the application, to avoid keeping the input\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    571\u001b[0m         \u001b[0;31m# arguments in memory\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 572\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    573\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    574\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/STAT-440/nft/jason/venv/lib/python3.9/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    260\u001b[0m         \u001b[0;31m# change the default number of processes to -1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    261\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mparallel_backend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_n_jobs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 262\u001b[0;31m             return [func(*args, **kwargs)\n\u001b[0m\u001b[1;32m    263\u001b[0m                     for func, args, kwargs in self.items]\n\u001b[1;32m    264\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/STAT-440/nft/jason/venv/lib/python3.9/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    260\u001b[0m         \u001b[0;31m# change the default number of processes to -1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    261\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mparallel_backend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_n_jobs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 262\u001b[0;31m             return [func(*args, **kwargs)\n\u001b[0m\u001b[1;32m    263\u001b[0m                     for func, args, kwargs in self.items]\n\u001b[1;32m    264\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/STAT-440/nft/jason/venv/lib/python3.9/site-packages/sklearn/utils/fixes.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    209\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    210\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mconfig_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 211\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunction\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    212\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    213\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/STAT-440/nft/jason/venv/lib/python3.9/site-packages/sklearn/model_selection/_validation.py\u001b[0m in \u001b[0;36m_fit_and_score\u001b[0;34m(estimator, X, y, scorer, train, test, verbose, parameters, fit_params, return_train_score, return_parameters, return_n_test_samples, return_times, return_estimator, split_progress, candidate_progress, error_score)\u001b[0m\n\u001b[1;32m    679\u001b[0m             \u001b[0mestimator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    680\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 681\u001b[0;31m             \u001b[0mestimator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    682\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    683\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/STAT-440/nft/jason/venv/lib/python3.9/site-packages/sklearn/linear_model/_stochastic_gradient.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, coef_init, intercept_init, sample_weight)\u001b[0m\n\u001b[1;32m   1535\u001b[0m             \u001b[0mFitted\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0mSGDRegressor\u001b[0m\u001b[0;31m`\u001b[0m \u001b[0mestimator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1536\u001b[0m         \"\"\"\n\u001b[0;32m-> 1537\u001b[0;31m         return self._fit(\n\u001b[0m\u001b[1;32m   1538\u001b[0m             \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1539\u001b[0m             \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/STAT-440/nft/jason/venv/lib/python3.9/site-packages/sklearn/linear_model/_stochastic_gradient.py\u001b[0m in \u001b[0;36m_fit\u001b[0;34m(self, X, y, alpha, C, loss, learning_rate, coef_init, intercept_init, sample_weight)\u001b[0m\n\u001b[1;32m   1483\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mt_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1.0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1484\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1485\u001b[0;31m         self._partial_fit(\n\u001b[0m\u001b[1;32m   1486\u001b[0m             \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1487\u001b[0m             \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/STAT-440/nft/jason/venv/lib/python3.9/site-packages/sklearn/linear_model/_stochastic_gradient.py\u001b[0m in \u001b[0;36m_partial_fit\u001b[0;34m(self, X, y, alpha, C, loss, learning_rate, max_iter, sample_weight, coef_init, intercept_init)\u001b[0m\n\u001b[1;32m   1413\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_average_intercept\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat64\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0morder\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"C\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1414\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1415\u001b[0;31m         self._fit_regressor(\n\u001b[0m\u001b[1;32m   1416\u001b[0m             \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0malpha\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mC\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlearning_rate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_iter\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1417\u001b[0m         )\n",
      "\u001b[0;32m~/Documents/STAT-440/nft/jason/venv/lib/python3.9/site-packages/sklearn/linear_model/_stochastic_gradient.py\u001b[0m in \u001b[0;36m_fit_regressor\u001b[0;34m(self, X, y, alpha, C, loss, learning_rate, sample_weight, max_iter)\u001b[0m\n\u001b[1;32m   1616\u001b[0m             \u001b[0maverage_intercept\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m  \u001b[0;31m# Not used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1617\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1618\u001b[0;31m         coef, intercept, average_coef, average_intercept, self.n_iter_ = _plain_sgd(\n\u001b[0m\u001b[1;32m   1619\u001b[0m             \u001b[0mcoef\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1620\u001b[0m             \u001b[0mintercept\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "g_search.fit(x_train, y_train);\n",
    "print(g_search.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5f767eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "### New model"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
